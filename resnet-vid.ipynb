{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7448002,"sourceType":"datasetVersion","datasetId":4335306}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-21T14:18:24.39161Z","iopub.execute_input":"2024-01-21T14:18:24.391977Z","iopub.status.idle":"2024-01-21T14:18:26.827352Z","shell.execute_reply.started":"2024-01-21T14:18:24.391947Z","shell.execute_reply":"2024-01-21T14:18:26.82635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.python.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2024-01-21T14:18:37.923356Z","iopub.execute_input":"2024-01-21T14:18:37.923818Z","iopub.status.idle":"2024-01-21T14:18:49.394599Z","shell.execute_reply.started":"2024-01-21T14:18:37.923787Z","shell.execute_reply":"2024-01-21T14:18:49.393503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = 512\nBATCH_SIZE = 32\nCHANNELS = 3\nEPOCHS = 5","metadata":{"execution":{"iopub.status.busy":"2024-01-21T14:19:27.157795Z","iopub.execute_input":"2024-01-21T14:19:27.159018Z","iopub.status.idle":"2024-01-21T14:19:27.164494Z","shell.execute_reply.started":"2024-01-21T14:19:27.158983Z","shell.execute_reply":"2024-01-21T14:19:27.162318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    \"/kaggle/input/pgdataset/PG\",\n    shuffle = True,\n    image_size = (IMAGE_SIZE, IMAGE_SIZE),\n    batch_size = BATCH_SIZE\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T14:19:29.534684Z","iopub.execute_input":"2024-01-21T14:19:29.535047Z","iopub.status.idle":"2024-01-21T14:19:33.991595Z","shell.execute_reply.started":"2024-01-21T14:19:29.535018Z","shell.execute_reply":"2024-01-21T14:19:33.99066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = dataset.class_names\nclass_names","metadata":{"execution":{"iopub.status.busy":"2024-01-21T14:19:36.757958Z","iopub.execute_input":"2024-01-21T14:19:36.758373Z","iopub.status.idle":"2024-01-21T14:19:36.765785Z","shell.execute_reply.started":"2024-01-21T14:19:36.758339Z","shell.execute_reply":"2024-01-21T14:19:36.764698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T14:19:41.856925Z","iopub.execute_input":"2024-01-21T14:19:41.857348Z","iopub.status.idle":"2024-01-21T14:19:41.865593Z","shell.execute_reply.started":"2024-01-21T14:19:41.857316Z","shell.execute_reply":"2024-01-21T14:19:41.864632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n\n    ds_size = len(ds)\n\n    if shuffle:\n        ds = ds.shuffle(shuffle_size, seed = 12)\n        \n    train_size = int(train_split*ds_size)\n    val_size = int(val_split*ds_size)\n    \n    train_ds = ds.take(train_size)\n    \n    val_ds = ds.skip(train_size).take(val_size)\n    test_ds = ds.skip(train_size).skip(val_size)\n    \n    return train_ds, val_ds, test_ds","metadata":{"execution":{"iopub.status.busy":"2024-01-21T14:20:03.556884Z","iopub.execute_input":"2024-01-21T14:20:03.557256Z","iopub.status.idle":"2024-01-21T14:20:03.564044Z","shell.execute_reply.started":"2024-01-21T14:20:03.557213Z","shell.execute_reply":"2024-01-21T14:20:03.563068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T14:20:05.100819Z","iopub.execute_input":"2024-01-21T14:20:05.101524Z","iopub.status.idle":"2024-01-21T14:20:05.117676Z","shell.execute_reply.started":"2024-01-21T14:20:05.101488Z","shell.execute_reply":"2024-01-21T14:20:05.116828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\nval_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\ntest_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T14:20:08.983519Z","iopub.execute_input":"2024-01-21T14:20:08.984135Z","iopub.status.idle":"2024-01-21T14:20:09.003834Z","shell.execute_reply.started":"2024-01-21T14:20:08.984104Z","shell.execute_reply":"2024-01-21T14:20:09.002702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Rescaling images if user inputted img is not according to required format\nresize_and_rescale = tf.keras.Sequential([\n    layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n    layers.experimental.preprocessing.Rescaling(1.0/255)\n])","metadata":{"execution":{"iopub.status.busy":"2024-01-21T14:20:09.927655Z","iopub.execute_input":"2024-01-21T14:20:09.928378Z","iopub.status.idle":"2024-01-21T14:20:09.958209Z","shell.execute_reply.started":"2024-01-21T14:20:09.928345Z","shell.execute_reply":"2024-01-21T14:20:09.957316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    layers.experimental.preprocessing.RandomRotation(0.2),\n])","metadata":{"execution":{"iopub.status.busy":"2024-01-21T14:20:11.544335Z","iopub.execute_input":"2024-01-21T14:20:11.545208Z","iopub.status.idle":"2024-01-21T14:20:11.556439Z","shell.execute_reply.started":"2024-01-21T14:20:11.545159Z","shell.execute_reply":"2024-01-21T14:20:11.55556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet_model = Sequential()\n\npretrained_model = tf.keras.applications.ResNet50(include_top = False,\n                                                   input_shape = (512, 512, 3),\n                                                   pooling = 'avg', classes = 2,\n                                                   weights = 'imagenet')\nfor layer in pretrained_model.layers:\n    layer.trainable = False\n\nresnet_model.add(pretrained_model)\nresnet_model.add(Flatten())\nresnet_model.add(Dense(512, activation = 'relu'))\nresnet_model.add(Dense(2, activation = 'softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-01-21T14:20:24.294772Z","iopub.execute_input":"2024-01-21T14:20:24.295123Z","iopub.status.idle":"2024-01-21T14:20:27.614077Z","shell.execute_reply.started":"2024-01-21T14:20:24.295094Z","shell.execute_reply":"2024-01-21T14:20:27.613167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-21T14:20:32.443375Z","iopub.execute_input":"2024-01-21T14:20:32.443732Z","iopub.status.idle":"2024-01-21T14:20:32.486698Z","shell.execute_reply.started":"2024-01-21T14:20:32.443704Z","shell.execute_reply":"2024-01-21T14:20:32.48569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet_model.compile(\n    optimizer = 'adam',\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n    metrics = ['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T14:20:35.010798Z","iopub.execute_input":"2024-01-21T14:20:35.011156Z","iopub.status.idle":"2024-01-21T14:20:35.03387Z","shell.execute_reply.started":"2024-01-21T14:20:35.011127Z","shell.execute_reply":"2024-01-21T14:20:35.033132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = resnet_model.fit(\n    train_ds,\n    validation_data = val_ds,\n    epochs = 10\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T14:20:42.066425Z","iopub.execute_input":"2024-01-21T14:20:42.067169Z","iopub.status.idle":"2024-01-21T14:32:10.144936Z","shell.execute_reply.started":"2024-01-21T14:20:42.067139Z","shell.execute_reply":"2024-01-21T14:32:10.144044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = resnet_model.evaluate(test_ds)\nscores","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:11:35.453289Z","iopub.execute_input":"2024-01-21T15:11:35.453669Z","iopub.status.idle":"2024-01-21T15:11:55.697676Z","shell.execute_reply.started":"2024-01-21T15:11:35.453639Z","shell.execute_reply":"2024-01-21T15:11:55.696387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:11:58.808418Z","iopub.execute_input":"2024-01-21T15:11:58.809078Z","iopub.status.idle":"2024-01-21T15:11:58.814114Z","shell.execute_reply.started":"2024-01-21T15:11:58.809047Z","shell.execute_reply":"2024-01-21T15:11:58.81309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function takes model and image as input and tells what is predicted class and confidence\n'''def predict(model, img):\n    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n    img_array = tf.expand_dims(img_array, 0)  # Create a batch\n\n    predictions = model.predict(img_array)\n\n    predicted_class = class_names[np.argmax(predictions[0])]\n    confidence = round(100 * (np.max(predictions[0])), 2)\n    return predicted_class, confidence'''","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:12:04.466926Z","iopub.execute_input":"2024-01-21T15:12:04.467581Z","iopub.status.idle":"2024-01-21T15:12:04.473835Z","shell.execute_reply.started":"2024-01-21T15:12:04.467548Z","shell.execute_reply":"2024-01-21T15:12:04.472778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Function takes model and image as input and tells what is predicted class and confidence\ndef predict(model, frame):\n    img_array = cv2.resize(frame, (224, 224))\n    img_array = tf.keras.preprocessing.image.img_to_array(img_array)\n    img_array = tf.expand_dims(img_array, 0)  # Create a batch\n\n    predictions = model.predict(img_array)\n\n    predicted_class = np.argmax(predictions[0])\n    confidence = round(100 * np.max(predictions[0]), 2)\n    return predicted_class, confidence\n","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:25:10.940501Z","iopub.execute_input":"2024-01-21T15:25:10.940883Z","iopub.status.idle":"2024-01-21T15:25:11.121888Z","shell.execute_reply.started":"2024-01-21T15:25:10.940853Z","shell.execute_reply":"2024-01-21T15:25:11.12109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Process the video and count the number of detections\ndef process_video(video_path, model):\n    cap = cv2.VideoCapture(video_path)\n    frame_width = int(cap.get(3))\n    frame_height = int(cap.get(4))\n    out = cv2.VideoWriter('output_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10, (frame_width, frame_height))\n\n    counter = 0  # Counter for the number of detections\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Perform prediction on the frame\n        predicted_class, confidence = predict(model, frame)\n\n        # You can use the predicted_class and confidence as needed\n        print(f\"Predicted Class: {predicted_class}, Confidence: {confidence}%\")\n\n        # Count the number of detections\n        if confidence > 0.5:  # Adjust the confidence threshold as needed\n            counter += 1\n\n        # Write the frame to the output video\n        out.write(frame)\n\n        cv2.imshow('Image Classification', frame)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n\n    # Release resources\n    cap.release()\n    out.release()\n    cv2.destroyAllWindows()\n\n    print(\"Total number of detections:\", counter)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:28:12.93132Z","iopub.execute_input":"2024-01-21T15:28:12.932308Z","iopub.status.idle":"2024-01-21T15:28:12.940534Z","shell.execute_reply.started":"2024-01-21T15:28:12.932274Z","shell.execute_reply":"2024-01-21T15:28:12.939579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the model version\nexisting_versions = [int(i) for i in os.listdir(\"/kaggle/working/\") if i.isdigit()]\nmodel_version = max(existing_versions + [0]) + 1\n\n# Save the model to the Kaggle working directory\nresnet_model.save(f\"/kaggle/working/{model_version}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:28:40.62864Z","iopub.execute_input":"2024-01-21T15:28:40.628994Z","iopub.status.idle":"2024-01-21T15:28:59.713074Z","shell.execute_reply.started":"2024-01-21T15:28:40.628967Z","shell.execute_reply":"2024-01-21T15:28:59.712068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"/kaggle/working/output\", 'zip', \"/kaggle/working/\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:33:27.899914Z","iopub.execute_input":"2024-01-21T15:33:27.900704Z","iopub.status.idle":"2024-01-21T15:33:40.133938Z","shell.execute_reply.started":"2024-01-21T15:33:27.900673Z","shell.execute_reply":"2024-01-21T15:33:40.132973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}